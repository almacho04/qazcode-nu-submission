{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM API — Getting Started\n",
    "\n",
    "This notebook shows how to call the **GPT-OSS** model hosted on `hub.qazcode.ai`.\n",
    "\n",
    "The server uses the **OpenAI-compatible API**, so you can use the `openai` Python library or plain `requests`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m120 packages\u001b[0m \u001b[2min 0.54ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m114 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95370b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"YOUR_API_KEY\"  # replace with your key\n",
    "HUB_URL = \"URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=HUB_URL,\n",
    "    api_key=API_KEY,  # replace with your key\n",
    ")\n",
    "\n",
    "MODEL = \"oss-120b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello! Who are you?\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System Prompt + User Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a medical diagnosis assistant. Given patient symptoms, suggest the most probable diagnosis with an ICD-10 code.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Patient presents with fever, dry cough, and shortness of breath lasting 5 days.\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Structured JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a clinical decision support system.\n",
    "Given patient symptoms, return a JSON object:\n",
    "{\n",
    "  \"diagnoses\": [\n",
    "    {\"rank\": 1, \"icd_code\": \"...\", \"name\": \"...\", \"explanation\": \"...\"},\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "Return top 3 diagnoses ranked by likelihood. Respond with JSON only.\"\"\"\n",
    "\n",
    "symptoms = \"Severe headache, nausea, vomiting, neck stiffness, sensitivity to light.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": symptoms},\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = json.loads(response.choices[0].message.content)\n",
    "for d in result[\"diagnoses\"]:\n",
    "    print(f\"[{d['rank']}] {d['icd_code']} — {d['name']}\")\n",
    "    print(f\"    {d['explanation']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://{}/chat/completions\".format(HUB_URL),\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"oss-120b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(response.json()[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c1516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qazcode-nu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
